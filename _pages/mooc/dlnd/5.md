---
layout: page
title: "DLND: 5. Training Neural Network"
permalink: /mooc/dlnd/5/
---

In the [last lesson](/mooc/dlnd/3), we learned the theory behind **Neural Networks**. In practice, there are a lot of obstacles in successful training a neural network to guess. In this lesson, we will learn about the problem of **overfitting** and **underfitting** and the possible techniques to overcome this problem.

### Testing

Often, it is hard to compare two models and declare one is better than the other. For example, in the example below, there are two models fitting the same data. The linear model in the left is simpler but misclassifies some data. The model in the right classifies all data correctly but is substantially more complex. Which model should we choose?

![Overfitting and Underfitting](/assets/mooc/dlnd/5/overfit_underfit.png)

To make the choice objective, it is essential to divide the labeled data into two parts: the **train set** and the **test set**. We only use the training set to train the model, and then only use the **test set** to evaluate the model.

![Training and Test Sets](/assets/mooc/dlnd/5/train_and_test.png)

For the two models below, only 1 of the 4 points were misclassified in the left, whereas 2 of the 4 points were misclassified in the right, so we choose the model in the left.

![Result of dividing into train and test sets](/assets/mooc/dlnd/5/train_test_result.png)

### Overfitting and Underfitting

The example above could be generalized into the fundamental problem in machine learning: overfitting and underfitting. Let's use a simple dataset below where 6 objects are labeled into two groups. The correct classification is dogs vs. not dogs

![Correct model](/assets/mooc/dlnd/5/correct_model.png)

**Overfitting** is a problem of using overly complex model, thereby modeling not only the trend but also the noise from the data. We also say that this model has **high variance**. An overfitting model does well on the train set, but performs poorly on the test set because it is too specific (too fit) to the train set.  For example, if the test set had a black dog, it would falsely categorize it with the apple, toaster, and cat. In other words, it fails to generalize.

![Overfitting model](/assets/mooc/dlnd/5/overfitting_model.png)

 **Underfitting**, in contrast, is a problem of using overly simple model, resulting in a high error.  The classification *animals vs. not animals* would be an underfit model. We also say that this model has **high bias**. An underfitting model fits neither the train set nor the test set well.

![Underfitting model](/assets/mooc/dlnd/5/underfitting_model.png)

In neural network, the overfitting-underfitting problem would look something like this:

![Problem in neural network setting](/assets/mooc/dlnd/5/underfit_overfit.png)

The linear model is too simple to accurately classify the training set. The complex model classifies the training set really well, but it will fail to generalize.

In general, we prefer overfitting models rather than underfitting models, because there are several techniques to fix overfitting models. These techniques are called **Regularization**.

### Early Stopping

One of the regularization techniques is called **Early Stopping**. As the name suggests, we stop training the neural network early. To understand why this technique, we need to understand how neural network is trained.

**Epochs** are the number of times the entire dataset was used to train the model. The more epochs the model is trained through, the lower the cost function is. However, if we use a high variance model, as we go through epochs, the neural network starts overfitting: capturing not only the general trend of the training set but also the specific traits of the data in the training set.

![Overfitting in high epochs](/assets/mooc/dlnd/5/epochs_overfit.png)

Now, let's try to plot the error function for each of these models in the training set and test set. The training error decreases as we train the model more, but the test error decreases until we start overfitting the model. This plot is called the **Model Complexity Graph**.

![Plot of error functions](/assets/mooc/dlnd/5/training_test_error_plot.png)

The Early Stopping technique is simple: we train the model until testing error starts to increase.

### L2 Regularization

Another regularization technique is called **L2 Regularization**. This technique penalizes large weights. Again, let's use another example to understand why this technique mitigates overfitting.

![Split two points](/assets/mooc/dlnd/5/split_two_points.png)

Consider a simple problem of splitting two points $(1, 1)$ and $(-1, -1)$. We have two models $\sigma(x_1 + x_2)$ and $\sigma(10x_1 + 10x_2)$.

![Line between two points](/assets/mooc/dlnd/5/split_two_points_line.png)

Both $x_1 + x_2 = 0$ and $10x_1 + 10x_2 = 0$ specify exactly same boundary: a line that passes the origin with slope $-1$. However, the two models give different predictions.

$$
\sigma(1 + 1) \simeq 0.88 \\
\sigma(-1 -1) \simeq 0.12 \\
\sigma(10 + 10) \simeq 0.9999999979 \\
\sigma(-10 - 10) \simeq 0.0000000021
$$

Thus, the second model gives a smaller error $y - \hat{y}$.

![Sigmoid function](/assets/mooc/dlnd/5/split_two_points_sigmoid.png)

However, the second model suffers from a subtle problem. Its sigmoid activation function almost always returns results to 0 and 1. (X-axis is $x_1 + x_2$). Thus, in most places, the gradient is close to 0, so gradient descent makes very little difference at each step.

Thus, we want to penalize large weights. To do this, we add an additional term to the error function. This additional term is the sum of squares of weights. This is called the L2 regularization because we the sum of squares is known as the L2 norm in math. We scale this term with $\lambda$, the **regularization term**.

$$
E = -\frac{1}{m} \sum_{i=1}^m (1-y_i) \log (1-\hat{y_i}) + y_i \log(\hat{y_i}) + \lambda \sum_{j=1}^n w_j^2
$$

Another popular regularization is L1 regularization. As the name suggests, we use L1 norm instead of the L2 norm.

$$
E = -\frac{1}{m} \sum_{i=1}^m (1-y_i) \log (1-\hat{y_i}) + y_i \log(\hat{y_i}) + \lambda \sum_{j=1}^n \lvert w_j \rvert
$$

L1 and L2 regularization has a different preference in weight vectors, so we should choose the norm according to our objective. L1 regularization is better for feature selection (choosing which features are worth keeping), whereas L2 regularization is better for general training.

| L1                              | L2                                         |
| ------------------------------- | ------------------------------------------ |
| Smaller weights go to $0$       | Make weight homogeneously small            |
| Results in sparse weight vector | Results in dense vector with similar sizes |
| Good for feature selection      | Normally better for training models        |
| $(1, 0, 0, 1, 0)$               | $(0.5, 0.3, -0.2, 0.4, 0.1)$               |



### Dropout

Yet another regularization technique is called **Dropout regularization**. In this regularization, on every epoch we randomly "drop out" some parts of the network when training. By dropout, we mean that we don't factor certain perceptrons in the feed-forward or backpropagation process.

Without dropout, the output could be dominated by certain perceptrons of the layer. Then, the perceptrons that heavily influence the output have heavy weights, so they will be updated more than the ones with low influence.

![Problem without Dropout](/assets/mooc/dlnd/5/dropout_problem.png)

However, if we dropout randomly, sometimes the perceptrons with high weights would be "turned off" in the calculation. Then, we are able to train other perceptrons which had comparatively low weights.

The dropout regularization has one parameter: the probability each node will be dropped.


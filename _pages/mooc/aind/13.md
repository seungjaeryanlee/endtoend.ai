---
layout: page
title: "AIND: 13. Extending Minimax Search"
permalink: /mooc/aind/13/
---

In [Lesson 11](/mooc/aind/11) and [Lesson 12](/mooc/aind/12), we learned about **Minimax Search**. However, we only used it in a two-player, deterministic, fully observable (perfect information) game. In this lesson, we extend minimax search to games beyond this limitations.

### 3-Player Games

Consider Isolation with 3 players. The same rules apply, so the game continues until there is one winner.

![3-Player Isolation]({{ "assets/mooc/aind/13/3_player_isolation.png" | absolute_url }})

Then, we can't use "minimax" anymore since we have 3 players. Instead, we use a similar variant called **MAXN** where we evaluate the board for each player and propagate it up the tree by maximizing the score for the player to play next.

![Tree for 3 Players]({{ "assets/mooc/aind/13/3_player_tree.png" | absolute_url }})

### 3-Player Pruning

In 3-Player game, *deep* alpha-beta pruning is not possible, but a *shallow* alpha-beta pruning is possible.

 pruning can work on 3-player games if every evaluation value has a lower bound and the sums of evaluation values for each player has a upper bound. ([Korf 1991](https://pdfs.semanticscholar.org/ec08/284de3ac57f72e3aa931881808c322be5edc.pdf)) In the case of 3-Player Isolation with the evaluation function $\text{# of my moves}$, $0$ is a natural lower bound, and there exists some upper bound $u$ for the sum. For the example, let's assume $u = 10$.

![Example of Shallow Pruning]({{ "assets/mooc/aind/13/shallow_pruning.png" | absolute_url }})

For example, in the tree above, Player 2 finds that one move will return a score of $10$. Since that is the upper bound, no other move can return a better score, so it can prune the rest of the moves.

![Another example of Shallow Pruning]({{ "assets/mooc/aind/13/shallow_pruning_2.png" | absolute_url }})

Then, in the second child of Player 1, Player 2's best move leads to value $(3, 7, 0)$. Therefore, Player 1's best move is guaranteed to have a score of at least 3, and since $u = 10$, that best move will have score at most 7 for Player 2 and Player 3.

Then, when we look at the third child of Player 1, we see the score $(1, 7, 2)$. Therefore, Player 2's best move is guaranteed to have a score of at least 7, and again, since $u = 10$, that best move will have score at most 3 for Player 1 and Player 3. However, Player 1 already has found a move that guarantees score of 3, so it not make this move. Therefore, we can prune this branch.

### Probabilistic Games

Unlike Isolation or Chess where the result of every action is decided (**deterministic**), there are games like Backgammon where the result varies by probability (**stochastic**).

To discuss probabilistic games, we will use a variant of Isolation called Sloppy Isolation. For every move a player makes, it has 10% chance of undershooting the goal and 10% chance of overshooting the goal, unless it cannot undershoot or overshoot the goal because it is filled in already.

![Rule of Sloppy Isolation 1]({{ "assets/mooc/aind/13/sloppy_isolation.png" | absolute_url }})

![Rule of Sloppy Isolation 2]({{ "assets/mooc/aind/13/sloppy_isolation_2.png" | absolute_url }})

### Expectimax

For probabilistic games, we need to modify the game tree. Each action can now have multiple possible results, so we introduce a probability node (marked in green) to the tree. 

![Game Tree for Sloppy Isolation]({{ "assets/mooc/aind/13/sloppy_isolation_tree.png" | absolute_url }})

The evaluation values are propagated up with probabilities taken into account.

Note that in stochastic environment, the evaluation function has another factor of complexity. For example, if every move would likely end in a loss, perhaps it is better to move so that the opponent is more likely to make a mistake or be unlucky.

### Expectimax Alpha-Beta Pruning

It is possible to prune the game tree in stochastic environment. Again, we need to know the bounds of the evaluation function to prune. Suppose that the range is $[-10, 10]$.

![Example of alpha-beta pruning for Expectimax]({{ "assets/mooc/aind/13/expectimax_pruning.png" | absolute_url }})

Consider the tree above. We evaluate $6.5$ for the first move of Player 1. For the second move of Player 1, the first branch has a value of $0$. Therefore, the evaluation score for the second move is $E = 0.5 \times 0 + 0.5 \times v$, but $v < 10$, so $E < 5$. Therefore, the first move is guaranteed to have a better score than the second move, so we can prune the second move.

Note that for any node $A$, it is beneficial to evaluate values for branches with high probabilities, since it will most effectively constrain the evaluation value of $A$. Thus, we are more likely to be able to prune the succeeding branches.

![Another example of alpha-beta pruning for Expectimax]({{ "assets/mooc/aind/13/expectimax_pruning_ex.png" | absolute_url }})


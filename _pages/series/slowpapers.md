---
layout: papers
title: "Slow Papers"
permalink: /slowpapers/
redirect_from:
 - /tags/slowpapers/
 - /blog/tags/slowpapers/

papers:
  # - title: Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards
  #   authors: Vecerik et al. (2017)
  #   url: /slowpapers/leveraging-demonstrations-for-deep-reinforcement-learning-on-robotics-problems-with-sparse-rewards/
  #   image_url: /papers/covers/leveraging-demonstrations-for-deep-reinforcement-learning-on-robotics-problems-with-sparse-rewards.png
  # - title: "Asynchronous Methods for Deep Reinforcement Learning"
  #   authors: Mnih et al. (2016)
  #   url: /slowpapers/a3c/
  #   image_url: /annotations/covers/a3c.png
  - title: "The Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
    authors: Juliani et al. (2019)
    url: /slowpapers/obstacle-tower/
    image_url: /annotations/covers/obstacle-tower.png
  - title: Exploration by Random Network Distillation
    authors: Burda et al. (2018)
    url: /slowpapers/rnd/
    image_url: /annotations/covers/rnd.png
  - title: A Deeper Look at Experience Replay
    authors: Zhang and Sutton (2017)
    url: /slowpapers/cer/
    image_url: /annotations/covers/cer.png
  - title: Neural Fitted Q Iteration
    authors: Riedmiller (2005)
    url: /slowpapers/nfq/
    image_url: /annotations/covers/nfq.png
---

**Slow Papers** is a series of posts that explain important papers in machine learning and deep learning. With Slow Papers, you will be able to gain a deep understanding of the papers behind important theoretical and practical results in machine learning and deep learning.

---
layout: post
title: "AIND: 2. Constraint Satisfaction Problems"
permalink: /mooc/aind/2
---

### Constraint Satisfaction Problem

A **Constraint Satisfaction Problem** (CSP) consists of three sets that define the problem:

* Set of **variables**
* Set of **domains** that specify the possible values of each variable
* Set of **constraints** that limit the value of each variable

### Examples

CSP can be used in variety of problems. due to its flexibility. Here are some examples where CSP can be used to solve the problem along with the three sets that define CSP.

#### Sudoku

![An example of Sudoku]({{ "assets/mooc/aind/2/sudoku.png" | absolute_url }})

Sudoku is a puzzle with a 81 boxes shaped 9-by-9. The 9-by-9 grid is partitioned into 9 3-by-3 squares. The goal of Sudoku is to fill all 81 boxes with a number from 1 to 9. Each row and column of the grid must have the digits 1-9 exactly once. Also, each 3-by-3 square must also have the digit 1-9 exactly once.

**CSP Definition**

* **Variables**: The 81 boxes of the Sudoku puzzle.
* **Domains**: 1 to 9
* **Constraints**: Each row, column, and 3x3 square must contain digits 1-9.

#### $N$-Queens

![An example of N-Queens]({{ "assets/mooc/aind/2/8-queens.png" | absolute_url }})

$N$-Queens is a problem where given an $N$-by-$N$ board, you want to place $N$ Queens such that no two Queens are in the same row, column or diagonal. 

**CSP Definition**

- **Variables**: The row assignment of $N$ queens
- **Domains**: 1 to $N$
- **Constraints**: No two queen can be on the same row or diagonal

#### Map Coloring

![An example of a Map Coloring]({{ "assets/mooc/aind/2/map-coloring.png" | absolute_url }})

Map coloring is a problem where given a map and a set of colors, you color the regions of the map such that no adjacent regions have the same color. (This is related to the chromatic number of the graph in Graph Theory.)

**CSP Definition**

- **Variables**: The color of each region of the map.
- **Domains**: The list of colors.
- **Constraints**: No two adjacent regions can be colored the same color.

 ### Constraint Graph

![The constraint graph for the map coloring CSP]({{ "assets/mooc/aind/2/constraint-graph.png" | absolute_url }})

For the map coloring problem, the constraints can be represented as a graph. This is called the **Constraint Graph**. The variables are the nodes of the graph, and the constraints are the edges of the graph. The graph structure allows us to use efficient algorithms to solve the CSP.

### Constraint Types

Constraints can be categorized by the number of variables it involves. A **unary constraint** is a constraint that limits the value of one variable (T cannot be colored green). A **binary constraint** is a constraint that limits the value of two variables (V and NSW cannot have the same color).

Constraints can also be categorized as **hard constraints** and **soft constraints**. Hard constraints are constraints that must be satisfied, whereas soft constraints need not be satisfied. Although soft constraints can be left unsatisfied, it will be penalized since we would prefer solutions that also satisfy soft constraints if possible. 

For example, in the map coloring CSP, we could add a soft constraint that each color should be used approximately same times so that it looks aesthetically pleasing.

### Backtracking Search

The **Backtracking search** is the easiest algorithm to solve CSP. The solver incrementally assigns values to variables. If the solver reaches a state where the assignment cannot reach the solution, the solver **backtracks** to try a different assignment.

Let's use the backtracking search on Sudoku. Assign some number to the first variable so that all constraints are satisfied. Then, assign the second variable with some number. Suppose that after a few steps, the solver finds out for the $k$-th variable, there is no digit left to assign. Then, the solver abandons this assignment and backtracks and tries a different $k-1$-th variable and continues to assign values to variables.

Suppose that the solver tries all possible numbers left to assign the $k-1$-th variable but all assignments are abandoned. Then, the solver backtracks once again and assigns a different value to the $k-2$-th example. The process continues until a solution is found.

![Backtracking Animation in Sudoku]({{ "assets/mooc/aind/2/backtracking-sudoku.gif" | absolute_url }})

### Improving Backtracking Efficiency

There are serveral ways to make backtracking more efficient. We can use **Least Constraining Value** to choose the best value to assign, and we can use **Minimum Remaining Values** and **Degree Heuristic** to choose the next variable to assign value. We can also use **Forward Checking**, **Constraint Propagation** and **Arc Consistency** to detect failure early.

#### Least Constraining Value

![Least Constraining Value]({{ "assets/mooc/aind/2/least_constraining_value.png" | absolute_url }})

One possible optimization for backtracking is to choose the value that constrains  the remaining the value the least.

#### Minimum Remaining Values (MRV)

![Minimum Remaining Values]({{ "assets/mooc/aind/2/minimum_remaining_values.png" | absolute_url }})

Another optimization for backtracking is to prioritize assignment of variable that has fewest remaining valid values.

#### Degree Heuristic

![Degree Heuristic]({{ "assets/mooc/aind/2/degree_heuristic.png" | absolute_url }})

In the case that there are multiple variables that satisfy MRV, choose the variable that has the most constraints on unassigned variables.

#### Forward Checking

![Forward Checking]({{ "assets/mooc/aind/2/forward_checking.gif" | absolute_url }})

Another optimization technique is **Forward Checking**. For each variable, we store possible values and update them as we search.

#### Constraint Propagation

However, forward checking doesn't detect all failures early on. In the example above, we could have known that the assignment should be abandoned just by observing that although NT and SA are adjacent, they both only have blue left.

#### Arc Consistency

**Arc Consistency** is a simple version of Constraint Propagation. We say that a variable A is **arc-consistent** with respect to variable B ($ A \to B$) if after choosing any value for A, the variable B still can be assigned some value. If this is true for all variables, we say that the network is **arc-consistent**.

Constraint Propagation is implemented with a Queue of pairs of variables. When a value is assigned to a variable $v$, we add $(v, n_1), (v, n_2), \ldots$ to the Queue, where $n_1, n_2, \ldots$ are neighbors of $v$. Then, we pop a pair $(a, b)$ from the Queue and check the arc-consistencies $a \to b$ and $b \to a$. If either of them is inconsistent we remove values from the list of possible values for $a$ or $b$ to make them both arc-consistent. Suppose we changed the list for $a$. Then we add $(a, m_1), (a, m_2), \ldots$ to the Queue where $m_1, m_2, \ldots$ are neighbors of $a$. (Same for $b$). The process continues until the Queue is empty or some variable has no possible value.

#### Arc Consistency Example

![Constraining Propagation]({{ "assets/mooc/aind/2/constraint_propagation.gif" | absolute_url }})

Let's return to the example. After assigning Green to variable Q, we check its neighbors and remove Green from them. Out of the three neighbors NSW, SA, NT, we choose to check NSW first. The Queue might look something like this:

* (NSW, SA)
* (NSW, V)
* (NSW, Q)
* (SA, NT)
* ...

![]({{ "assets/mooc/aind/2/arc_consistency_1.gif" | absolute_url }})

Consider the pair (NSW, SA). First, we check SA -> NSW. When SA is assigned blue, NSW can be assigned red, so SA is arc-consistent with respect to NSW.

![]({{ "assets/mooc/aind/2/arc_consistency_2.gif" | absolute_url }})

 However, for NSW -> SA, when NSW is assigned blue, SA cannot be assigned any value. Therefore, to make the network arc-consistent, we remove the value blue from NSW.

![]({{ "assets/mooc/aind/2/arc_consistency_3.gif" | absolute_url }})

Now we get look at the pair (NSW, V). NSW -> V is arc-consistent, but, V -> NSW is not arc-consistent, so we remove red from V's list of possible values.

![]({{ "assets/mooc/aind/2/arc_consistency_4.gif" | absolute_url }})

(NSW, Q) is arc-consistent, so we look at (SA, NT). SA -> NT is not arc-consistent, so we remove Blue from SA. SA has no possible value, so we conclude that the assignment is invalid.

#### Structured CSPs

If we know the certain features of the structure of the CSP, we can significantly optimize the problem.

![Constraint Graph with two separate subgraphs]({{ "assets/mooc/aind/2/constraint-graph.png" | absolute_url }})

In this case, T is independent of the rest of the problem, so we can solve it separately.

![Topological Sort of Constraint Tree]({{ "assets/mooc/aind/2/structured_csp_flatten.png" | absolute_url }})

Or if we know that the Constraint Graph is a tree (has no loops), we can significantly optimize the problem using **Topological Sort**. First, we choose any variable as a root. Then, we create an ordering of variables  from root to leaves such that every node's parent appears before its child in the ordering. 

With this ordering, it is easy to solve the problem. We start at the last variable (F) and make each parent arc-consistent. If this is impossible, the problem does not have a solution. Otherwise, we start with the first variable (A) and assign values down the ordering. Because the tree is arc-consistent, the assignment will solve the CSP. 

This process is $O(ND^2)$, where $N$ is the number of variables and $D$ is the size of the domain. This is much faster compared to $O(N^D)$ for general CSPs.

![Transforming Constraint Graph to Tree]({{ "assets/mooc/aind/2/convert_to_tree.png" | absolute_url }})

Even if the Constraint Graph is not a tree, you might be able to change it into a tree by assigning values to a few variables. For the Australia example, if you assign a value to SA first, you can topologically sort the rest and solve it faster.
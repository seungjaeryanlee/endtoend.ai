# Site settings
title: endtoendAI
description: > # this means to ignore newlines until "baseurl:"
  We seek to provide high quality information on different aspects of Artificial
  Intelligence, including Machine Learning, Deep Learning, Reinforcement
  Learning, and Computer Vision.
baseurl: "" # the subpath of your site, e.g. /blog/
url: "https://www.endtoend.ai" # the base hostname & protocol for your site

twitter_username: seungjaeryanlee
github_username:  jekyll

title_image: /favicon.png

# Layout settings
header_type: default  # values [ drawer, default ]
post_type: highlight    # values [ highlight, default ]
pagination_type: default  # values [ ops, default ]

disqus: true
# disqus_shortname: 'www.endtoend.ai'

# Build settings
markdown: kramdown
# kramdown:
#   parse_block_html: true

# Put all pages except index.md in _pages directory
include:
 - "_pages"

plugins:
 - jekyll-redirect-from

featured_page:
  # link: /blog/gsoc/7
  # title: "GSoC TensorFlow Part 7: Retrospective"
  # supporting_text: "As of August 27th, the Google Summer of Code coding phase is officially over. In this post, I look back at the summer, reviewing my accomplishments and shortcomings. Because I will continue contributing to TensorFlow and TF-Agents, I also outline my plans for the next fall."
  # image_url: /assets/blog/gsoc/gsoc_tensorflow.png
  # cover_or_contain: contain
  # tags:
  #     - reinforcement-learning
  #     - gsoc
  #     - tensorflow
  link: /rl-weekly/37
  title: "RL Weekly 37: Observational Overfitting, Hindsight Credit Assignment, and Procedurally Generated Environment Suite"
  supporting_text: "In this issue, we look at Google and MIT's study on the observational overfitting phenomenon and how overparametrization helps generalization, a new family of algorithms using hindsight credit assignment by DeepMind, and a new environment suite by OpenAI consisting of procedurally generated environments."
  image_url: /assets/blog/rl-weekly/37/obs_overfit.png
  cover_or_contain: contain
  tags:
    - reinforcement-learning
    - rl-weekly
  # link: /blog/neurips2019-rl
  # title: "Reinforcement Learning Papers Accepted to NeurIPS 2019"
  # supporting_text: "I have compiled a list of 184 reinforcement learning papers accepted to NeurIPS 2019."
  # image_url: /assets/blog/misc/neurips2019-rl/neurips.png
  # cover_or_contain: contain
  # tags:
  #   - reinforcement-learning

front_page_links:
  - name: "RL Weekly"
    url: "/rl-weekly/"
    image: "/assets/home/rl-weekly.png"
    image_type: contain
    description: >
      Get the highlights of reinforcement learning in both research and industry
      every week.
  # - name: "CTRL: Current Topics in RL"
  #   url: "/ctrl/"
  #   image: "/assets/home/ctrl.png"
  #   image_type: contain
  #   description: >
  #     Read summaries of new papers in Reinforcement Learning, ranging from
  #     theoretical studies to experiments.
  - name: "Slow Papers"
    url: "/slowpapers/"
    image: "/assets/home/microscope.png"
    image_type: contain
    description: >
      Read extended explanations of seminal papers.
  - name: "Fast Papers"
    url: "/fastpapers/"
    image: "/assets/home/ctrl.png"
    image_type: contain
    description: >
      Read summaries of key ideas from a wide variety of papers.
  # - name: Resources
  #   url: "/resources"
  #   image: "/assets/home/resources.png"
  #   image_type: contain
  #   description: >
  #     Presentation slides, snipplets of code, and other useful resources for
  #     studying reinforcement learning.
  - name: "Blog"
    url: "/blog/"
    image: "/assets/home/blog.png"
    image_type: contain
    description: >
      We blog about our AI-related experience, including internships, 
      competitions, and research.
  # - name: "AI for Prosthetics"
  #   url: "/ai-for-prosthetics/"
  #   image: "/assets/_pages/ai-for-prosthetics/card.jpg"
  #   image_type: cover
  #   description: >
  #     This is a guide for the NIPS 2018 AI for Prosthetics challenge with a 
  #     helper package and a series of blog posts.
  # - name: "Atari Environments"
  #   url: "/envs/gym/atari/"
  #   image: "/assets/home/atari.jpeg"
  #   image_type: cover
  #   description: >
  #     Read about state-of-the-art results for each environment of Atari 2600,
  #     the standard suite for analyzing performance of various Reinforcement
  #     Learning methods.
  # - name: "MuJoCo Environments"
  #   url: "/envs/gym/mujoco/"
  #   image: "/assets/home/mujoco.png"
  #   image_type: cover
  #   description: >
  #     Read about continuous control environments created with MuJoCo, a
  #     proprietary physics engine for detailed, efficient rigid body simulations
  #     with contacts.
  # - name: "Sutton and Barto Notebooks"
  #   url: "/sutton-barto-notebooks/"
  #   image: "/assets/home/sutton-barto.png"
  #   image_type: contain
  #   description: >
  #     This repository contains Jupyter Notebook of implementations of insightful
  #     figures in Sutton and Barto's <i>Reinforcement Learning: An Introduction
  #     </i>.
  # - name: "Slides"
  #   url: "/slides/"
  #   image: "/assets/home/slides.png"
  #   image_type: contain
  #   description: >
  #     This is a collection of presentation slides summarizing contents of books
  #     and state-of-the-art results.
  # - name: "DQN Book"
  #   url: "https://www.dqnbook.org/"
  #   image: "/assets/home/dqn.png"
  #   image_type: cover
  #   description: >
  #     Read the early draft of the Deep Q-Networks (DQN) book. This book
  #     explores various improvements of DQN that achieved superhuman results.
  # - name: "Policy Gradient Book"
  #   url: "https://www.policygradientbook.org/"
  #   image: "/assets/home/pg.png"
  #   image_type: contain
  #   description: >
  #     Read the early draft of the Policy Gradient book. Policy gradient methods
  #     are used in various state-of-the-art reinforcement learning applications.
